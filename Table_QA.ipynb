{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNuQVKVeVrDmMFYnZiOTBKv",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AdopleAIOrg/Table-Question-Answering/blob/main/Table_QA.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gSoUZszCkoAv"
      },
      "outputs": [],
      "source": [
        "!pip install -r /content/requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile app.py\n",
        "import streamlit as st\n",
        "import pandas as pd\n",
        "import tempfile\n",
        "from transformers import AutoModelForSeq2SeqLM, AutoModelForTableQuestionAnswering, AutoTokenizer, pipeline\n",
        "\n",
        "class TableQuestionAnswering:\n",
        "    \"\"\"\n",
        "    A class that performs table question answering using the TAPAS model.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        \"\"\"\n",
        "        Initializes the TableQuestionAnswering class by loading the TAPAS model and tokenizer.\n",
        "        \"\"\"\n",
        "\n",
        "        model_tapas = \"google/tapas-large-finetuned-wtq\"\n",
        "        tokenizer_tapas = AutoTokenizer.from_pretrained(model_tapas)\n",
        "        self.pipe_tapas = pipeline(\"table-question-answering\", model=model_tapas, tokenizer=tokenizer_tapas)\n",
        "\n",
        "    def _processing_file(self, query: str, file: str, correct_answer: str) -> str:\n",
        "        \"\"\"\n",
        "        Processes the uploaded file and generates an answer for the given query using the TAPAS model.\n",
        "\n",
        "        Args:\n",
        "            query (str): The question to ask about the table.\n",
        "            file (str): The path to the uploaded file.\n",
        "            correct_answer (str): The correct answer (optional).\n",
        "\n",
        "        Returns:\n",
        "            str: The generated answer.\n",
        "        \"\"\"\n",
        "\n",
        "        table = pd.read_csv(file.name).astype(str).fillna('')\n",
        "        result_tapas = self.pipe_tapas(table=table, query=query)\n",
        "        return result_tapas['answer']\n",
        "\n",
        "    def _generate_answer(self, query: str, file: str, correct_answer: str) -> str:\n",
        "        \"\"\"\n",
        "        Generates an answer for the given query and file using the TAPAS model.\n",
        "\n",
        "        Args:\n",
        "            query (str): The question to ask about the table.\n",
        "            file (str): The path to the uploaded file.\n",
        "            correct_answer (str): The correct answer (optional).\n",
        "\n",
        "        Returns:\n",
        "            str: The generated answer.\n",
        "        \"\"\"\n",
        "\n",
        "        excel_file = pd.read_excel(file.name)\n",
        "        excel_file.to_csv(f\"{file.name}.csv\",index=False)\n",
        "        file_name = f\"{file.name}.csv\"\n",
        "        table = pd.read_csv(file_name).astype(str).fillna('')\n",
        "        result_tapas = self.pipe_tapas(table=table, query=query)\n",
        "        return result_tapas['answer']\n",
        "\n",
        "    def streamlit_interface(self):\n",
        "        \"\"\"\n",
        "        Creates the Streamlit interface for the Table QA application.\n",
        "        \"\"\"\n",
        "\n",
        "        # Set up the Streamlit app\n",
        "        st.set_page_config(page_title=\"Streamlit Table QA\")\n",
        "\n",
        "        st.title(\"Table QA\")\n",
        "        input_file = st.file_uploader(\"Upload a CSV file\", type=['csv','xlsx'])\n",
        "\n",
        "        if input_file is not None:\n",
        "            with tempfile.NamedTemporaryFile(delete=False) as temp_file:\n",
        "                temp_file.write(input_file.read())\n",
        "                temp_file.flush()\n",
        "                query = st.text_input(\"Enter a question\")\n",
        "                if query != \"\":\n",
        "                    st.write(\"Selected file: \", input_file.name)\n",
        "                    if input_file.name.endswith('.csv'):\n",
        "                      result_answer = self._processing_file(query, temp_file, \"\")\n",
        "                      st.write(\"Answer:\", result_answer)\n",
        "                    elif input_file.name.endswith('.xlsx'):\n",
        "                      result_answer = self._generate_answer(query, temp_file, \"\")\n",
        "                      st.write(\"Answer:\", result_answer)\n",
        "                else:\n",
        "                    st.write(\"Please enter a query\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "\n",
        "    table_qa = TableQuestionAnswering()\n",
        "    table_qa.streamlit_interface()"
      ],
      "metadata": {
        "id": "YnSTiNdklYG-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!streamlit run app.py & npx localtunnel --port 8501"
      ],
      "metadata": {
        "id": "FhtsYSPFoF8u"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}